{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yagmail\n",
    "import datetime\n",
    "import re\n",
    "import jieba\n",
    "import numpy as np\n",
    "import datetime\n",
    "from time import sleep\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json\n",
    "\n",
    "filenames = [\n",
    "    \"杭州 20240601_20240701 51551 条.csv\"\n",
    "]\n",
    "\n",
    "# 百度的Key导入 ################################################################################################\n",
    "# 数据输入 2 装有key的csv文件\n",
    "keys = [\n",
    "    pd.read_csv(\"data\\key\\KongBaiduAccesskey1.csv\"),\n",
    "    pd.read_csv(\"data\\key\\KongBaiduAccesskey2.csv\"),\n",
    "    pd.read_csv(\"data\\key\\KongBaiduAccesskey3.csv\"),\n",
    "    pd.read_csv(\"data\\key\\XinBaiduAccesskey2.csv\")\n",
    "]\n",
    "\n",
    "# 初始化key索引\n",
    "key_index = 0\n",
    "\n",
    "def get_current_key():\n",
    "    global key_index\n",
    "    key = keys[key_index]\n",
    "    API_KEY = key[\"API_KEY\"][0]\n",
    "    SECRET_KEY = key[\"SECRET_KEY\"][0]\n",
    "    key_index = (key_index + 1) % len(keys)  # 更新key索引，实现循环\n",
    "    return API_KEY, SECRET_KEY\n",
    "\n",
    "def get_access_token():\n",
    "    \"\"\"\n",
    "    使用 AK，SK 生成鉴权签名（Access Token）\n",
    "    :return: access_token，或是None(如果错误)\n",
    "    \"\"\"\n",
    "    API_KEY, SECRET_KEY = get_current_key()\n",
    "    url = \"https://aip.baidubce.com/oauth/2.0/token\"\n",
    "    params = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": API_KEY,\n",
    "        \"client_secret\": SECRET_KEY,\n",
    "    }\n",
    "    return str(requests.post(url, params=params).json().get(\"access_token\"))\n",
    "\n",
    "def baidu_nlp(text):\n",
    "    url = (\n",
    "        \"https://aip.baidubce.com/rpc/2.0/nlp/v1/sentiment_classify?charset=UTF-8&access_token=\"\n",
    "        + get_access_token()\n",
    "    )\n",
    "    params = {\"access_token\": \"your_access_token\", \"text\": text}\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\"}\n",
    "\n",
    "    response = requests.request(\"POST\", url, data=json.dumps(params), headers=headers)\n",
    "\n",
    "    result = json.loads(response.text)\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    for item in result[\"items\"]:\n",
    "        confidence = item[\"confidence\"]\n",
    "        negative_prob = item[\"negative_prob\"]\n",
    "        positive_prob = item[\"positive_prob\"]\n",
    "        sentiment = item[\"sentiment\"]\n",
    "\n",
    "    return confidence, negative_prob, positive_prob, sentiment\n",
    "\n",
    "def clean_content(content, place):\n",
    "    # 去除地名\n",
    "    content = content.replace(place, \"\")\n",
    "    # 去除一些关键词\n",
    "    content = (\n",
    "        content.replace(\"分享图片\", \"\")\n",
    "        .replace(\"分享视频\", \"\")\n",
    "        .replace(\"微博视频\", \"\")\n",
    "        .replace(\"的微博视频\", \"\")\n",
    "        .replace(\"网页链接\", \"\")\n",
    "        .replace(\"超话\", \"\")\n",
    "        .replace(\"新浪图片\", \"\")\n",
    "        .replace(\"<br>\", \"\")\n",
    "        .replace(\"的秒拍视频\", \"\")\n",
    "    )\n",
    "    # 去除英文\n",
    "    content = re.sub(r\"[a-zA-Z]+\", \"\", content)\n",
    "    content = (\n",
    "        re.sub(r\"\\d+\", \"\", content).replace(\" \", \"\").replace(\".\", \"\").replace(\"_\", \"\")\n",
    "    )\n",
    "    # 去除所有非中文符号\n",
    "    content = re.sub(r\"[^\\u4e00-\\u9fa5]\", \"\", content)\n",
    "    # 去除空白字符\n",
    "    content = re.sub(r\"\\s+\", \"\", content)\n",
    "    return content\n",
    "\n",
    "for filename in filenames:\n",
    "\n",
    "    ###############################################只需要修改filename即可，确定好datainputpath和dataoutputpath这两个文件夹与该py文件的相对位置\n",
    "    # filename = \"杭州 20200701_20200801 18378 条.csv\"\n",
    "    print(filename)\n",
    "    ###############################################注意命名格式是否正确 与csv的名字对应好\n",
    "    datainputpath = \"data/杭州按月分类文件_201901_202406/\"\n",
    "    dataoutputpath = \"data/杭州按月分类文件_201901_202406_情绪值/\"\n",
    "    ###############################################设置好的输入输出文件所在文件夹路径\n",
    "\n",
    "    ########################### 自己设置区 ###############################\n",
    "    emailhost = \"smtp.qq.com\"\n",
    "    emailname = \"473161189@qq.com\"\n",
    "    emailpassword = \"hspxxpupkwowbggg\"  # 授权码 需要到邮箱的设置里面 开启授权\n",
    "    #####################################################################\n",
    "\n",
    "    # 发送者的邮箱名和授权码以及host\n",
    "    yag = yagmail.SMTP(user=emailname, password=emailpassword, host=emailhost)\n",
    "    # 被发送的邮箱名和内容\n",
    "    yag.send(\n",
    "        to=emailname,\n",
    "        subject=\"开始\",\n",
    "        contents=\"爬取文本信息\\n\" + \"运行时间\" + f\"{filename}\",\n",
    "    )\n",
    "\n",
    "    # 数据输入 1 待提取情绪值的csv文件\n",
    "    data = pd.read_csv(datainputpath + filename)\n",
    "    tailname = \"_Baidu.csv\"  # 尾名 处理提取sentiment值后的文件\n",
    "\n",
    "    print(\"数据行数 \", len(data))  # 数据的行数\n",
    "    data.sample(2)  # 查看2\n",
    "\n",
    "    # 进行数据清洗、情绪值提取#############################################################################\n",
    "\n",
    "    time_start = time.time()\n",
    "    print(\"开始 \", datetime.datetime.now())\n",
    "\n",
    "    # 对content列进行清洗 由对应的地名在文本中去除content文本中的内容\n",
    "    data[\"clean_content\"] = data.apply(\n",
    "        lambda row: clean_content(row[\"content\"], row[\"content_location_name\"]), axis=1\n",
    "    )\n",
    "    print(\"清洗完成 \" + str(len(data)))\n",
    "\n",
    "    # 如果文本为空 去掉该行\n",
    "    data = data[data[\"clean_content\"] != \"\"]\n",
    "    print(\"去除空白行完成 \" + str(len(data)))\n",
    "\n",
    "    # 保留文本字数大于3的和小于512的文本   限制上，百度是512字、腾讯是200字\n",
    "    data = data[\n",
    "        (data[\"clean_content\"].apply(lambda x: len(x) < 512))\n",
    "        & (data[\"clean_content\"].apply(lambda x: len(x) > 3))\n",
    "    ]\n",
    "    print(\"保留字数大于3完成 \" + str(len(data)))\n",
    "\n",
    "    # 对清洗后的文本 进行 分词 放入jieba_cut列中\n",
    "    data[\"jieba_cut\"] = data[\"clean_content\"].apply(lambda x: jieba.lcut(x))\n",
    "    print(\"分词完成 \" + str(len(data)))\n",
    "\n",
    "    def process_row(row):\n",
    "        try:\n",
    "            confidence, negative, positive, sentiment = baidu_nlp(row[\"clean_content\"])\n",
    "            sleep(0.05)  # 大量测试 0.1算比较合适 可以适当减少\n",
    "            return confidence, negative, positive, sentiment\n",
    "        except:\n",
    "            print(row[\"publish_time\"] + \" \" + row[\"clean_content\"])\n",
    "            print(\"百度API调用失败\")\n",
    "            return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    tqdm.pandas()\n",
    "    results = data.progress_apply(process_row, axis=1)\n",
    "    try:\n",
    "        (\n",
    "            data[\"baidu_confidence\"],\n",
    "            data[\"baidu_negative\"],\n",
    "            data[\"baidu_positive\"],\n",
    "            data[\"baidu_sentiment\"],\n",
    "        ) = zip(*results)\n",
    "        # 保存\n",
    "        with open(\n",
    "            dataoutputpath + filename.split(\".\")[0] + tailname,\n",
    "            \"w\",\n",
    "            encoding=\"utf-8-sig\",\n",
    "            newline=\"\",\n",
    "        ) as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(data.columns)  # 写入列名\n",
    "            for row in data.itertuples(index=False):\n",
    "                writer.writerow(row)\n",
    "\n",
    "        print(data.head(5))\n",
    "        time_end = time.time()\n",
    "        print(\n",
    "            filename,\n",
    "            \"\\n本次运行总共耗时：\",\n",
    "            time_end - time_start,\n",
    "            \"\\n即：\",\n",
    "            (time_end - time_start) / 60,\n",
    "            \"分钟\",\n",
    "            \"\\n即：\",\n",
    "            (time_end - time_start) / 3600,\n",
    "            \"小时\",\n",
    "        )\n",
    "        print(\"结束\", datetime.datetime.now())\n",
    "        yag.send(\n",
    "            to=emailname,\n",
    "            subject=\"结束\",\n",
    "            contents=filename\n",
    "            + \"爬取文本信息\\n\"\n",
    "            + \"运行时间\"\n",
    "            + f\"{time_end-time_start}\",\n",
    "        )\n",
    "    except:\n",
    "        print(\"百度API调用失败，将results保存后退出\")\n",
    "        results.to_csv(\"error\" + filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"情感分析完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

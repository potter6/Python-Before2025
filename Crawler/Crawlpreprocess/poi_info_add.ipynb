{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "{'ok': 0, 'msg': '这里还没有内容', 'data': {'cards': []}}\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到1条微博\n",
      "获取到1条微博\n",
      "获取到1条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到1条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到1条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到1条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到1条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到1条微博\n",
      "获取到1条微博\n",
      "获取到1条微博\n",
      "获取到2条微博\n",
      "获取到1条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n",
      "获取到2条微博\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import transformer\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import csv\n",
    "import random\n",
    "import json\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    \"Chrome/78.0.3904.108 Safari/537.36\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"cookie\": \"_T_WM=95312399235; XSRF-TOKEN=3a31a4; WEIBOCN_FROM=1110006030; SCF=AqAA_hXhYzgggeI_jiVgO_sAtey7ebyoB0r2lIfovSCppuC-IMQSaL-eEiD20ySrP_9VisloRCBQLI6yErrA_VI.; SUB=_2A25Lq1k5DeRhGeFP4lMR8SvIyTmIHXVoydTxrDV6PUJbktCOLWnzkW1NQOrKxXaGJKpvyPl0o-n9E8GC9sXW8mxg; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WFJf.nPypequXxyIBhJbGay5NHD95QNeK.peh2fShzfWs4DqcjPi--ci-z0i-2Ei--NiKn4i-z41h.Eehzt; SSOLoginState=1722755433; ALF=1725347433; MLOGIN=1; mweibo_short_token=c0319b197f; M_WEIBOCN_PARAMS=lfid%3D231583%26luicode%3D20000174%26uicode%3D20000174\",\n",
    "}\n",
    "\n",
    "# 高德API 请求地址前缀\n",
    "req_url_pref = \"https://restapi.amap.com/v3/geocode/geo?\"\n",
    "amp_api_key = '61c256acd1b853e34a6b9a31033c399d'\n",
    "amp_api_city='上海市'\n",
    "page=1\n",
    "\n",
    "def GaoDeLocation(address):\n",
    "        # 没有上海市的地址在前面加上上海市\n",
    "        if address.find(\"上海市\") == -1:\n",
    "            address = \"上海市\" + address\n",
    "        rep_params={\"key\":amp_api_key,\"address\":address,\"city\":amp_api_city}\n",
    "        response=requests.get(req_url_pref,params=rep_params)\n",
    "        locationinfo=response.json()\n",
    "        status=locationinfo[\"status\"]\n",
    "        if status !=\"0\":\n",
    "            outputaddress=locationinfo[\"geocodes\"][0][\"formatted_address\"]\n",
    "            gcj02_lng=float(locationinfo[\"geocodes\"][0][\"location\"].split(\",\")[0])\n",
    "            gcj02_lat=float(locationinfo[\"geocodes\"][0][\"location\"].split(\",\")[1])\n",
    "            wgs84_lng,wgs84_lat=transformer.gcj02towgs84(gcj02_lng,gcj02_lat)\n",
    "            wgs84_lng=float(wgs84_lng)\n",
    "            wgs84_lat=float(wgs84_lat)\n",
    "        else:\n",
    "            outputaddress=np.nan\n",
    "            gcj02_lng=np.nan\n",
    "            gcj02_lat=np.nan\n",
    "            wgs84_lng=np.nan\n",
    "            wgs84_lat=np.nan\n",
    "\n",
    "        return outputaddress,gcj02_lng,gcj02_lat,wgs84_lng,wgs84_lat\n",
    "\n",
    "def write_nameaddress_csv(filename, fields, data):\n",
    "    with open(filename, mode=\"a\", newline=\"\",encoding='utf-8-sig') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fields)\n",
    "        if file.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(data)\n",
    "\n",
    "def get_tweets(URL):\n",
    "    # url = URL.format(str(page))\n",
    "    url=URL.format(1)\n",
    "    while True:\n",
    "        try:\n",
    "            res = requests.get(url,headers=headers)\n",
    "            res.encoding = \"utf-8-sig\"\n",
    "            # print(res)\n",
    "\n",
    "            # 间隔时间\n",
    "            # sleep(random.randint(5, 9))\n",
    "            sleep(random.randint(2,4))\n",
    "            # soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "            jd = json.loads(res.text)\n",
    "            jd = res.json()\n",
    "\n",
    "        except:\n",
    "            print(\"代理有问题呀，换个ip试试\")\n",
    "            continue\n",
    "        if (jd[\"ok\"] == 0) and (\"这里还没有内容\" in str(jd)):\n",
    "            print(jd)\n",
    "            return 0\n",
    "        if jd[\"ok\"] == 0:\n",
    "            print(\"获取地点的页面失败啊，换个ip试试\")\n",
    "        else:\n",
    "            break\n",
    "    # 第一页的结果会有点不一样\n",
    "    if page == 1:\n",
    "        # if jd['data']['cards'][0]['card_id']=='card_hq_poiweibo':  #微博数据结构的表头为data——cards—— \"card_id\": \"card_hq_poiweibo\",\n",
    "        if (\n",
    "            jd[\"data\"][\"cards\"][0][\"card_id\"] == \"hot_search\"\n",
    "        ):  # 微博数据结构的表头为data——cards—— \"card_id\": \"card_hq_poiweibo\",\n",
    "            tweets = jd[\"data\"][\"cards\"]\n",
    "            # tweets=jd['data']['cards'][0]['card_group']\n",
    "        else:\n",
    "            tweets = jd[\"data\"][\"cards\"]  # 爬取city的这个地方我自己改为0了.\n",
    "            # tweets=jd['data']['cards'][1]['card_group']\n",
    "\n",
    "\n",
    "        name=jd[\"data\"][\"cardlistInfo\"][\"title_top\"]\n",
    "        address=jd[\"data\"][\"cardlistInfo\"][\"address\"]\n",
    "        subtitle=jd[\"data\"][\"cardlistInfo\"][\"sub_title\"]\n",
    "\n",
    "        # 没有上海市的地址在前面加上上海市\n",
    "        if address.find(\"上海市\") == -1:\n",
    "            address = \"上海市\" + address\n",
    "        rep_params={\"key\":amp_api_key,\"address\":address,\"city\":amp_api_city}\n",
    "        response=requests.get(req_url_pref,params=rep_params)\n",
    "        locationinfo=response.json()\n",
    "        status=locationinfo[\"status\"]\n",
    "        if status !=\"0\":\n",
    "            outputaddress=locationinfo[\"geocodes\"][0][\"formatted_address\"]\n",
    "            gcj02_lng=float(locationinfo[\"geocodes\"][0][\"location\"].split(\",\")[0])\n",
    "            gcj02_lat=float(locationinfo[\"geocodes\"][0][\"location\"].split(\",\")[1])\n",
    "            wgs84_lng,wgs84_lat=transformer.gcj02towgs84(gcj02_lng,gcj02_lat)\n",
    "            wgs84_lng=float(wgs84_lng)\n",
    "            wgs84_lat=float(wgs84_lat)\n",
    "        else:\n",
    "            outputaddress=np.nan\n",
    "            gcj02_lng=np.nan\n",
    "            gcj02_lat=np.nan\n",
    "            wgs84_lng=np.nan\n",
    "            wgs84_lat=np.nan\n",
    "\n",
    "        outputaddress,gcj02_lng,gcj02_lat,wgs84_lng,wgs84_lat=GaoDeLocation(address)\n",
    "\n",
    "        write_nameaddress_csv(\n",
    "            \"poi_info_added.csv\",\n",
    "            [\"name\", \"address\",\"subtitle\",\"outputaddress\",\"gcj02_lng\",\"gcj02_lat\",\"wgs84_lng\",\"wgs84_lat\"],\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"address\": address,\n",
    "                \"subtitle\":subtitle,\n",
    "                \"outputaddress\":outputaddress,\n",
    "                \"gcj02_lng\":gcj02_lng,\n",
    "                \"gcj02_lat\":gcj02_lat,\n",
    "                \"wgs84_lng\":wgs84_lng,\n",
    "                \"wgs84_lat\":wgs84_lat\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        tweets = jd[\"data\"][\"cards\"]\n",
    "        # tweets=jd['data']['cards'][0]['card_group']\n",
    "\n",
    "    print(\"获取到{}条微博\".format(len(tweets)))\n",
    "    return tweets\n",
    "\n",
    "for row in range(72):\n",
    "    global conn, cur, place, pid, category, category_id, total_id, city, city_id\n",
    "    # 读取资料文档\n",
    "    # f = pd.read_csv('data/pid.csv', encoding='gbk')  # 出错的话改成gbk\n",
    "    f = pd.read_csv(\"poi点位置信息补充.csv\",encoding='utf-8-sig')  # 出错的话改成gbk\n",
    "    # f = pd.read_csv(\"data\\shanghai.csv\")  # 出错的话改成gbk\n",
    "\n",
    "    place = f[\"pname\"][row]\n",
    "    pid = f[\"pid\"][row]\n",
    "    category = f[\"category\"][row]\n",
    "    category_id = f[\"category_id\"][row]\n",
    "    total_id = f[\"total_id\"][row]\n",
    "    city = f[\"city\"][row]\n",
    "    city_id = f[\"city_id\"][row]\n",
    "\n",
    "    URL = \"https://m.weibo.cn/api/container/getIndex?containerid=\" + pid + \"&page={}\"\n",
    "    time.sleep(random.randint(3, 6))\n",
    "    tweets = get_tweets(URL)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
